{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XHS Training Data Preparation\n",
        "\n",
        "Prepare XHS CSV data for model training:\n",
        "- Load collected + mock datasets\n",
        "- Normalize text into a model-ready field\n",
        "- Keep unlabeled pool separate\n",
        "- Create stratified train/val/test splits for labeled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segment 1: Imports and paths\n",
        "from pathlib import Path\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BASE_DIR = Path.cwd()\n",
        "COLLECTED_CSV = BASE_DIR / \"xhs_scraped_data_clean.csv\"\n",
        "MOCK_CSV = BASE_DIR / \"xhs_mock_training_data.csv\"\n",
        "OUT_DIR = BASE_DIR / \"training_data\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Base dir: {BASE_DIR}\")\n",
        "print(f\"Collected CSV exists: {COLLECTED_CSV.exists()}\")\n",
        "print(f\"Mock CSV exists: {MOCK_CSV.exists()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segment 3: Load and unify datasets\n",
        "frames = []\n",
        "\n",
        "if COLLECTED_CSV.exists():\n",
        "    collected = pd.read_csv(COLLECTED_CSV)\n",
        "    collected[\"source_file\"] = \"collected\"\n",
        "    if \"label_disruption\" not in collected.columns:\n",
        "        collected[\"label_disruption\"] = None\n",
        "    frames.append(collected)\n",
        "\n",
        "if MOCK_CSV.exists():\n",
        "    mock = pd.read_csv(MOCK_CSV)\n",
        "    mock[\"source_file\"] = \"mock\"\n",
        "    frames.append(mock)\n",
        "\n",
        "if not frames:\n",
        "    raise FileNotFoundError(\"No input CSVs found. Generate collected/mock CSVs first.\")\n",
        "\n",
        "df = pd.concat(frames, ignore_index=True)\n",
        "\n",
        "for col in [\"category\", \"filename\", \"window_title\", \"scraped_at\", \"raw\", \"cleaned\"]:\n",
        "    if col not in df.columns:\n",
        "        df[col] = \"\"\n",
        "\n",
        "# Utility functions\n",
        "SPECIAL_CHARS = re.compile(r\"[^\\w\\s\\u4e00-\\u9fff]\")\n",
        "\n",
        "def normalize_for_model(text: str) -> str:\n",
        "    text = str(text or \"\")\n",
        "    text = text.replace(\"/n\", \" \").replace(\"\\n\", \" \")\n",
        "    text = SPECIAL_CHARS.sub(\" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip().lower()\n",
        "    return text\n",
        "\n",
        "def safe_int_label(value):\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    text = str(value).strip()\n",
        "    if text in {\"0\", \"1\"}:\n",
        "        return int(text)\n",
        "    return None\n",
        "\n",
        "df[\"cleaned\"] = df[\"cleaned\"].fillna(\"\")\n",
        "df[\"raw\"] = df[\"raw\"].fillna(\"\")\n",
        "df[\"text_for_model\"] = df[\"cleaned\"].where(df[\"cleaned\"].str.strip() != \"\", df[\"raw\"])\n",
        "df[\"text_for_model\"] = df[\"text_for_model\"].apply(normalize_for_model)\n",
        "df[\"label_disruption\"] = df[\"label_disruption\"].apply(safe_int_label)\n",
        "\n",
        "print(f\"Total rows: {len(df)}\")\n",
        "print(df[[\"source_file\", \"label_disruption\"]].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Segment 4: Separate labeled and unlabeled pools\n",
        "labeled_df = df[df[\"label_disruption\"].isin([0, 1])].copy()\n",
        "unlabeled_df = df[~df[\"label_disruption\"].isin([0, 1])].copy()\n",
        "\n",
        "# Keep only useful training columns\n",
        "train_cols = [\n",
        "    \"category\",\n",
        "    \"filename\",\n",
        "    \"window_title\",\n",
        "    \"scraped_at\",\n",
        "    \"source_file\",\n",
        "    \"text_for_model\",\n",
        "    \"label_disruption\",\n",
        "]\n",
        "\n",
        "labeled_df = labeled_df[train_cols]\n",
        "unlabeled_cols = [col for col in train_cols if col != \"label_disruption\"]\n",
        "unlabeled_df = unlabeled_df[unlabeled_cols]\n",
        "\n",
        "print(f\"Labeled rows: {len(labeled_df)}\")\n",
        "print(f\"Unlabeled rows: {len(unlabeled_df)}\")\n",
        "if len(labeled_df) > 0:\n",
        "    print(labeled_df[\"label_disruption\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segment 5: Stratified split (70/15/15)\n",
        "if len(labeled_df) < 10:\n",
        "    raise ValueError(\"Not enough labeled rows to split reliably.\")\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    labeled_df,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=labeled_df[\"label_disruption\"],\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.50,\n",
        "    random_state=42,\n",
        "    stratify=temp_df[\"label_disruption\"],\n",
        ")\n",
        "\n",
        "print(f\"Train rows: {len(train_df)}\")\n",
        "print(f\"Val rows: {len(val_df)}\")\n",
        "print(f\"Test rows: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segment 6: Export model-ready CSV files\n",
        "train_path = OUT_DIR / \"train.csv\"\n",
        "val_path = OUT_DIR / \"val.csv\"\n",
        "test_path = OUT_DIR / \"test.csv\"\n",
        "labeled_path = OUT_DIR / \"labeled_full.csv\"\n",
        "unlabeled_path = OUT_DIR / \"unlabeled_pool.csv\"\n",
        "\n",
        "train_df.to_csv(train_path, index=False, encoding=\"utf-8\")\n",
        "val_df.to_csv(val_path, index=False, encoding=\"utf-8\")\n",
        "test_df.to_csv(test_path, index=False, encoding=\"utf-8\")\n",
        "labeled_df.to_csv(labeled_path, index=False, encoding=\"utf-8\")\n",
        "unlabeled_df.to_csv(unlabeled_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"Saved training-ready datasets:\")\n",
        "print(f\"- {train_path}\")\n",
        "print(f\"- {val_path}\")\n",
        "print(f\"- {test_path}\")\n",
        "print(f\"- {labeled_path}\")\n",
        "print(f\"- {unlabeled_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segment 7: Quick QA checks\n",
        "for name, part in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
        "    print(f\"\\n[{name}]\")\n",
        "    print(part[\"label_disruption\"].value_counts(normalize=True).sort_index())\n",
        "\n",
        "print(\"\\nSample training rows:\")\n",
        "display(train_df[[\"text_for_model\", \"label_disruption\"]].head(5))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
